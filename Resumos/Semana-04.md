# Semana 4: M√©todos de classifica√ß√£o supervisionada

## üìΩÔ∏è Videoaulas:
* [Videoaula 9 - Classifica√ß√£o de dados](https://www.youtube.com/watch?v=MU14rYb3l8c)
* [Videoaula 10 - Algoritmos de classifica√ß√£o](https://www.youtube.com/watch?v=de_lvW0VMMw)

---

## üìñ Texto-base:
* **Cap√≠tulo 5:** CASTRO, Daniel Gomes; FERRARI, Leandro Nunes de. **Introdu√ß√£o √† Minera√ß√£o de Dados:** Conceitos B√°sicos, Algoritmos e Aplica√ß√µes. Rio de Janeiro: Saraiva Uni, 2016;

---

## ‚úçÔ∏è Resumos e anota√ß√µes:

A tarefa de **predi√ß√£o** pode ser definida atrav√©s do ato de construir um modelo capaz de predizer os valores de sa√≠da de novos registros, 
utilizando como base os registros hist√≥ricos que j√° possuem um r√≥tulo de classe. Ela pode ser classificada em dois tipos: **classifica√ß√£o** ou 
**estima√ß√£o**.   

<img width="1596" height="576" alt="Tipos de predi√ß√£o" src="https://github.com/user-attachments/assets/6ae6fecb-b62f-492b-ac85-215980053df5" />   

*Fonte: Gerado com Napkin.AI a partir do texto-base e anota√ß√µes da aula.*  

O desenvolvimento de um **modelo preditivo** possu√≠ duas etapas principais:
* Treinamento: um preditor √© gerado a partir de um conjunto de dados rotulados (a sa√≠da desejada j√° √© conhecida). Esse preditor deve ser capaz de descrever e distinguir um conjunto predeterminado de classes e valores;
* Teste: o desempenho do preditor √© avaliado a partir do seu uso em dados n√£o utilizados durante a etapa de treinamento.

Na pr√°tica, existe uma fun√ß√£o que relaciona aquilo que √© observado ao resultado que se deseja prever. Caso se conhe√ßam apenas amostras dentro
dessa fun√ß√£o, haver√° um conjunto limitado de dados de treinamento, que muitas vezes podem possuir ru√≠dos. Durante a **Aprendizagem Supervisionada** procura-se uma fun√ß√£o substituta chamada de **modelo de aproxima√ß√£o**, que seja o mais pr√≥ximo poss√≠vel da fun√ß√£o real e desconhecida, medindo a dist√¢ncia entre a fun√ß√£o real e o modelo de aproxima√ß√£o. Essa dist√¢ncia √© chamada de **erro**.  

Existem dois erros importantes para a Aprendizagem Supervisionada:
* Erro de representa√ß√£o: "[...] o erro vai depender da adequa√ß√£o e do n√≠vel de flexibilidade do modelo preditivo em rela√ß√£o aos dados de treinamento, pois nem sempre ele √© suficientemente adequado para representar os dados". (CASTRO; FERRARI, 2016, p. 150);
* Erro de generaliza√ß√£o: "Esse erro surge, por exemplo, quando o modelo √© treinado em excesso e absorve os ru√≠dos dos dados de treinamento, sofrendo de uma sobregeneraliza√ß√£o dos resultados". (CASTRO; FERRARI, 2016, p. 151).

A figura exemplifica esses erros. A figura (a) apresenta um erro de representa√ß√£o, onde o modelo n√£o √© flex√≠vel o suficiente para representar o
conjunto dos objetos. A figura (b) indica um erro de generaliza√ß√£o: o modelo pode absorver os ru√≠dos contidos nos dados e apresentar baixa 
capacidade de generaliza√ß√£o. Por fim, a figura (c) apresenta um bom equ√≠librio entre *bias-vari√¢ncia*, ou seja, "[...] possui um baixo erro de 
treinamento gra√ßas √† flexibilidade do modelo e ao mesmo tempo n√£o 'interpola' os ru√≠dos da base". (CASTRO; FERRARI, 2016, p. 151)  

<img width="1285" height="472" alt="Erros na aprendizagem supervisionada" src="https://github.com/user-attachments/assets/31aa4033-9591-425a-a0e6-cd32bb1f9536" />  

*Fonte: CASTRO; FERRARI, 2016, p. 151*  

"Esse equil√≠brio entre o erro de representa√ß√£o e o erro de generaliza√ß√£o √© conhecido como o *dilema bias-vari√¢ncia* ou *efeito bias-vari√¢ncia*,
e constitui um problema central em aprendizagem supervisionada. O treinamento, portanto, feito de modo que o modelo capture as regularidades 
estat√≠sticas dos dados de treinamento, mas tamb√©m generalize bem para dados desconhecidos". (CASTRO; FERRARI, 2016, p. 151). O m√©todo mais usual
para manter esse equil√≠brio √© o uso da **valida√ß√£o cruzada**.  

Nesse m√©todo, os dados s√£o divididos em conjuntos de treinamento e teste. O modelo √© treinado iterativamente com o conjunto de 
treinamento e avaliado periodicamente no conjunto de teste. O treinamento √© interrompido se o erro de teste aumentar em itera√ß√µes consecutivas, e os par√¢metros do modelo com o melhor desempenho at√© o momento da interrup√ß√£o s√£o escolhidos como o resultado final.  

"Uma forma bastante comum de valida√ß√£o cruzada em minera√ß√£o de dados √© a chamada **valida√ß√£o cruzada em k-pastas** (k-fold cross-validation), 
que consiste em dividir a base de dados em k subconjuntos, sendo k‚Äì1 pastas para treinamento e 1 pasta para teste. Esse processo de treinamento 
e teste √© repetido com todos os k subconjuntos, e a m√©dia dos desempenhos para as bases de treinamento e as bases de teste √© adotada como 
indicador de qualidade do modelo". (CASTRO; FERRARI, 2016, p. 157). √â usual utilizar 10 pastas para estimar o erro, embora ainda existirem debatessobre o n√∫mero adequado de pastas. "[...] tamb√©m √© usual executar a valida√ß√£o em 10-pastas 10 vezes, o que implica treinar o algoritmo 100 vezes para uma base que corresponde a 9/10 da base completa e test√°-lo 100 vezes para uma base que corresponde a 1/10 da base completa". (CASTRO; FERRARI, 2016, p. 158).   

Outra forma comum de valida√ß√£o, especialmente em bases de dados com poucos objetos, √© a **valida√ß√£o cruzada leave-one-out** (LOOCV). Nela, apenas um objeto por vez √© utilizado para teste, enquanto os outros objetos s√£o utilizados para treinamento.   

### Avalia√ß√£o de desempenho da tarefa de Classifica√ß√£o

"Classifica√ß√£o √© a tarefa preditiva de identifica√ß√£o da classe √† qual um objeto pertence. Para que isso seja poss√≠vel, um modelo de classifica√ß√£o precisa ser constru√≠do, o que √© feito com base em um conjunto de treinamento previamente rotulado. O desempenho do classificador depende fortemente de sua flexibilidade (bias) e da qualidade de seu treinamento (vari√¢ncia). Entretanto, n√£o existe um classificador que seja melhor que todos os outros para todos os problemas de classifica√ß√£o". (CASTRO; FERRARI, 2016, ps. 158 e 159).   

Para isso, as medidas de desempenho dos classificadores poder√£o fornecer um valor quantitativo de sua qualidade, e devem considerar duas 
categorias de divis√£o de problemas: **problemas bin√°rios** e **problemas multiclasses**.

* **Problemas bin√°rios:** Existem apenas duas classes e, no geral, existe uma classe cujo valor se pretende predizer, chamada de *classe-alvo*.
  A classe-alvo, muitas vezes √© chamada de *classe positiva* e, em oposi√ß√£o, leva ao surgimento de uma *classe negativa*. Essas classes permitem
  definir alguns termos referentes √† elas:

   <img width="1357" height="490" alt="VP, VN, FP, FN" src="https://github.com/user-attachments/assets/cda7cea9-f524-4091-ae54-113cae83352b" />
  
  *Fonte: CASTRO; FERRARI, 2016, p. 160*

  A **Matriz de confus√£o** √© uma forma de representar essas classes, apresentando o desempenho de um algoritmo de classifica√ß√£o bin√°ria:

   <img width="1186" height="287" alt="Matriz de confus√£o" src="https://github.com/user-attachments/assets/af97e31d-03eb-48bf-a10c-a9f60c42ba0b" />

  *Fonte: CASTRO; FERRARI, 2016, p. 160*

  A partir dos valores apresentados na matriz de confus√£o, algumas taxas s√£o obtidas:
    - Taxa de verdadeiros positivos (TVP): percentual de objetos positivos classificados corretamente (TVP = VP / VP + FN);
    - Taxa de falsos positivos (TFP): percentual de objetos negativos classificados como positivos (TFP = FP / FP + VN);
    - Acur√°cia (ACC): taxa global de sucesso do algoritmo (n√∫mero de classifica√ß√µes corretas dividido pelo n√∫mero total de classifica√ß√µes);
    - Taxa de Erro (E): 1 - ACC;
    - Precis√£o (precision-Pr): foca na confiabilidade das previs√µes, mede a qualidade ou exatid√£o do algoritmo;
    - Revoca√ß√£o (recall-Re): foca na cobertura ou completude de um algoritmo;
      
      (Para entender melhor as medidas de Precis√£o e Revoca√ß√£o, imagine que uma equipe de buscas est√° procurando por pessoas perdidas dentro de uma floresta onde, ao mesmo tempo, existem tamb√©m turistas acampando. A *precis√£o* responder√° a pergunta: *"De todos os que a equipe de buscas trouxe de volta, quantos eram os que realmente estavam perdidos?"*; enquanto a *revoca√ß√£o* responder√°: "*De todas as pessoas que estavam realmente desaparecidas, quantas a equipe conseguiu encontrar?"*);
    - Score-F: medida que busca equilibrar a Precis√£o e a Revoca√ß√£o (F = 2 * Pr * Re / (Pr + Re));
    - Estat√≠stica Kappa: mede a concord√¢ncia entre as previs√µes do seu modelo e os valores reais, descontando a concord√¢ncia que ocorreria puramente por acaso.

* **Problemas Multiclasses:** Bases de dados com m√∫ltiplas classes. "Em um problema de predi√ß√£o multiclasse, a matriz de confus√£o possui nas linhas as classes originais e nas colunas, as classes preditas, sendo uma linha e uma coluna para cada classe. [...] um bom classificador deve apresentar n√∫meros maiores na diagonal principal e n√∫meros pequenos, idealmente zero, fora dela". (CASTRO; FERRARI, 2016, p. 164).

  A figura apresenta uma Matriz de confus√£o para um problema de classifica√ß√£o pra m√∫ltiplas classes:

  <img width="1363" height="387" alt="Matriz de confus√£o m√∫ltiplas classes" src="https://github.com/user-attachments/assets/1b4d2ece-efee-4c81-b15c-713c4ba04418" />

  *Fonte: CASTRO; FERRARI, 2016, p. 164*








